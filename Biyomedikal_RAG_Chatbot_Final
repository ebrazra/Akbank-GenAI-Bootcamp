import streamlit as st
import wikipedia
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA
import os
import openai

# API AnahtarÄ±nÄ±zÄ± Sisteme TanÄ±mlÄ±yoruz.
# NOT: Bu anahtarÄ±n aktif olmasÄ± ve kotasÄ±nÄ±n bulunmasÄ± gerekmektedir.
# API AnahtarÄ±nÄ± Ã‡evre DeÄŸiÅŸkeninden Okuma (GÃ¼venli YÃ¶ntem)
# Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in bu anahtarÄ± yerel sistem deÄŸiÅŸkenine ekleyin.
os.environ["OPENAI_API_KEY"] = os.environ.get("OPENAI_API_KEY")
openai.api_key = os.environ["OPENAI_API_KEY"] 

st.title("ğŸ”¬ Biyomedikal MÃ¼hendisliÄŸi Chatbot\'u (RAG)")
st.caption("Veri kaynaÄŸÄ±: Wikipedia | Model: GPT-3.5-Turbo")

@st.cache_resource
def get_vector_store():
    # Veri Ã‡ekme ve Veri TabanÄ± OluÅŸturma
    with st.spinner("Veri seti hazÄ±rlanÄ±yor..."):
        wikipedia.set_lang("en")
        try:
            wiki_page = wikipedia.page("Medical device", auto_suggest=False)
            raw_text = wiki_page.content
        except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):
            st.error("Wikipedia\'dan veri Ã§ekilemedi.")
            return None
        
        text_splitter = CharacterTextSplitter(separator="\n\n", chunk_size=1000, chunk_overlap=200)
        documents = text_splitter.split_text(raw_text)
        
        embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vector_store = Chroma.from_texts(
            texts=documents, embedding=embedding_model, persist_directory="./chroma_db"
        )
        st.success(f"VektÃ¶r Veri TabanÄ± baÅŸarÄ±yla oluÅŸturuldu. Toplam {len(documents)} belge eklendi.")
        return vector_store

def get_qa_chain(vector_store):
    llm = OpenAI(model_name="gpt-3.5-turbo-instruct", temperature=0)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vector_store.as_retriever(k=3)
    )
    return qa_chain

vector_store = get_vector_store()

if vector_store:
    qa_chain = get_qa_chain(vector_store)
    user_question = st.text_input("Biyomedikal mÃ¼hendisliÄŸi hakkÄ±nda bir soru sorabilirsin:")

    if user_question:
        with st.spinner("Cevap aranÄ±yor..."):
            try:
                response = qa_chain.run(user_question)
                st.markdown(f"**Chatbot CevabÄ±:** {response}")
            except Exception as e:
                # Kota hatasÄ±nÄ± yakalayacak kÄ±sÄ±m
                st.error("Sorgu hatasÄ±: API kotanÄ±z dolmuÅŸtur. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin.")
